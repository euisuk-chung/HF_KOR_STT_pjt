{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Install Dependencies (this may take about 2-3 min)\n",
    "\n",
    "# !pip install faster-whisper\n",
    "# !pip install yt-dlp\n",
    "\n",
    "import os, re\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from faster_whisper import WhisperModel\n",
    "from whisper.utils import get_writer\n",
    "from yt_dlp import YoutubeDL\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Faster-Whisper STT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import torch\n",
    "from faster_whisper import WhisperModel\n",
    "from yt_dlp import YoutubeDL\n",
    "\n",
    "def transcribe_audio(audio_dir=\"./contents\", output_dir=\"./outputs\", output_formats=[\"txt\", \"srt\"], \n",
    "                     mode=\"youtube\", whisper_model=\"base\", if_Colab=False):\n",
    "    \n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    compute_type = \"float16\" if device == \"cuda\" else \"int8\"\n",
    "    model = WhisperModel(whisper_model, device=device, compute_type=compute_type)\n",
    "\n",
    "    audio_dir = Path(audio_dir)\n",
    "    audio_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    output_dir = Path(output_dir)\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    if mode == \"youtube\":\n",
    "        YouTube_URL = input(\"Enter YouTube_URL\")  # @param {type:\"string\"}\n",
    "\n",
    "        def download_audio_from_youtube(url, file_name=None, out_dir=audio_dir):\n",
    "            print(f\"\\n==> Downloading audio with yt-dlp...\")\n",
    "            ydl_opts = {\n",
    "                'format': 'bestaudio/best',\n",
    "                'outtmpl': f\"{out_dir}/{file_name if file_name else '%(title)s.%(ext)s'}\",\n",
    "                'postprocessors': [{\n",
    "                    'key': 'FFmpegExtractAudio',\n",
    "                    'preferredcodec': 'mp3',\n",
    "                    'preferredquality': '192',\n",
    "                }],\n",
    "            }\n",
    "            with YoutubeDL(ydl_opts) as ydl:\n",
    "                ydl.download([url])\n",
    "                info_dict = ydl.extract_info(url, download=False)\n",
    "                file_path = ydl.prepare_filename(info_dict)\n",
    "                mp3_file_path = Path(file_path).with_suffix('.mp3')\n",
    "            \n",
    "            print(f\"File downloaded to {mp3_file_path}!\")\n",
    "            return str(mp3_file_path)\n",
    "\n",
    "        audio = download_audio_from_youtube(YouTube_URL)\n",
    "        print(\"\\n=======================\")\n",
    "        print(f\"\\nüîó YouTube URL: {YouTube_URL}\")\n",
    "        print(f\"\\nü§ñ Whisper Model: {whisper_model}\")\n",
    "        print(\"\\n=======================\")\n",
    "        \n",
    "    elif mode == \"local\":\n",
    "        mp3_files = list(audio_dir.glob(\"*.mp3\"))\n",
    "        \n",
    "        if len(mp3_files) == 0:\n",
    "            raise FileNotFoundError(f\"No .mp3 files found in the directory: {output_dir}\")\n",
    "        elif len(mp3_files) > 1:\n",
    "            raise FileExistsError(f\"Multiple .mp3 files found in the directory: {output_dir}. Please specify the file to use.\")\n",
    "        \n",
    "        audio = mp3_files[0]\n",
    "        print(\"\\n=======================\")\n",
    "        print(f\"\\nüîó Audio Path: {audio}\")\n",
    "        print(f\"\\nü§ñ Whisper Model: {whisper_model}\")\n",
    "        print(\"\\n=======================\")\n",
    "    else:\n",
    "        raise ValueError(\"Invalid mode. Please select either 'youtube' or 'local'.\")\n",
    "    \n",
    "    file_path = Path(audio)\n",
    "\n",
    "    print(f\"\\n==> Transcribing audio\")\n",
    "    segments, info = model.transcribe(str(file_path), beam_size=5)\n",
    "\n",
    "    # Save the transcription in the requested formats\n",
    "    for format in output_formats:\n",
    "        print(f\"\\n==> Creating .{format} file\")\n",
    "        output_file_path = output_dir / f\"{file_path.stem}.{format}\"\n",
    "        \n",
    "        with open(output_file_path, 'w', encoding='utf-8') as f:\n",
    "            if format == \"txt\":\n",
    "                for segment in segments:\n",
    "                    f.write(f\"{segment.text}\\n\")\n",
    "            elif format == \"srt\":\n",
    "                for i, segment in enumerate(segments, start=1):\n",
    "                    f.write(f\"{i}\\n\")\n",
    "                    f.write(f\"{self.format_timestamp(segment.start)} --> {self.format_timestamp(segment.end)}\\n\")\n",
    "                    f.write(f\"{segment.text}\\n\\n\")\n",
    "        \n",
    "        if if_Colab:\n",
    "            from google.colab import files\n",
    "            files.download(str(output_file_path))\n",
    "        else:\n",
    "            print(f\"Transcription saved as .{format} file at: {output_file_path}\")\n",
    "\n",
    "    print(\"\\n‚ú® All Done!\")\n",
    "    print(\"=======================\")\n",
    "    return segments\n",
    "\n",
    "def format_timestamp(seconds):\n",
    "    hours = int(seconds / 3600)\n",
    "    minutes = int((seconds % 3600) / 60)\n",
    "    seconds = seconds % 60\n",
    "    milliseconds = int((seconds - int(seconds)) * 1000)\n",
    "    return f\"{hours:02d}:{minutes:02d}:{int(seconds):02d},{milliseconds:03d}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Î°úÏª¨ ÏòàÏ†ú"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "619b0f7d813c42b5a1fd3bc9adf7b926",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.bin:   0%|          | 0.00/145M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ed0e59dba0a461dae967afb292ae8c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocabulary.txt:   0%|          | 0.00/460k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81c10eeeaead4f7189196fa2bba10f23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/2.31k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jasuc\\.virtualenvs\\HF_KOR_STT_pjt-LslUj6mJ\\lib\\site-packages\\huggingface_hub\\file_download.py:159: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\jasuc\\.cache\\huggingface\\hub\\models--Systran--faster-whisper-base. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f48e1386351c4471b2f12b8e4d368ca7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.20M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=======================\n",
      "\n",
      "üîó Audio Path: contents\\sample_sound.mp3\n",
      "\n",
      "ü§ñ Whisper Model: base\n",
      "\n",
      "=======================\n",
      "\n",
      "==> Transcribing audio\n",
      "\n",
      "==> Creating .txt file\n",
      "Transcription saved as .txt file at: outputs\\sample_sound.txt\n",
      "\n",
      "‚ú® All Done!\n",
      "=======================\n"
     ]
    }
   ],
   "source": [
    "result = transcribe_audio(mode=\"local\", output_formats=[\"txt\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Youtube ÏòàÏ†ú"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==> Downloading audio with yt-dlp...\n",
      "[youtube] Extracting URL: https://youtu.be/GEYxeMYMtE4\n",
      "[youtube] GEYxeMYMtE4: Downloading webpage\n",
      "[youtube] GEYxeMYMtE4: Downloading ios player API JSON\n",
      "[youtube] GEYxeMYMtE4: Downloading web creator player API JSON\n",
      "[youtube] GEYxeMYMtE4: Downloading player 57c75fa4\n",
      "[youtube] GEYxeMYMtE4: Downloading m3u8 information\n",
      "[info] GEYxeMYMtE4: Downloading 1 format(s): 251\n",
      "[download] Destination: outputs\\[ÏãúÍ≥ÑÏó¥] Ch1. Îç∞Ïù¥ÌÑ∞ÏôÄ Ïù∏Í≥µÏßÄÎä•, Í∑∏Î¶¨Í≥† Îç∞Ïù¥ÌÑ∞ Î∂ÑÏÑùÏù¥ÎûÄÔºü.webm\n",
      "[download] 100% of   16.03MiB in 00:00:06 at 2.43MiB/s   \n",
      "[ExtractAudio] Destination: outputs\\[ÏãúÍ≥ÑÏó¥] Ch1. Îç∞Ïù¥ÌÑ∞ÏôÄ Ïù∏Í≥µÏßÄÎä•, Í∑∏Î¶¨Í≥† Îç∞Ïù¥ÌÑ∞ Î∂ÑÏÑùÏù¥ÎûÄÔºü.mp3\n",
      "Deleting original file outputs\\[ÏãúÍ≥ÑÏó¥] Ch1. Îç∞Ïù¥ÌÑ∞ÏôÄ Ïù∏Í≥µÏßÄÎä•, Í∑∏Î¶¨Í≥† Îç∞Ïù¥ÌÑ∞ Î∂ÑÏÑùÏù¥ÎûÄÔºü.webm (pass -k to keep)\n",
      "[youtube] Extracting URL: https://youtu.be/GEYxeMYMtE4\n",
      "[youtube] GEYxeMYMtE4: Downloading webpage\n",
      "[youtube] GEYxeMYMtE4: Downloading ios player API JSON\n",
      "[youtube] GEYxeMYMtE4: Downloading web creator player API JSON\n",
      "[youtube] GEYxeMYMtE4: Downloading m3u8 information\n",
      "File downloaded to outputs\\[ÏãúÍ≥ÑÏó¥] Ch1. Îç∞Ïù¥ÌÑ∞ÏôÄ Ïù∏Í≥µÏßÄÎä•, Í∑∏Î¶¨Í≥† Îç∞Ïù¥ÌÑ∞ Î∂ÑÏÑùÏù¥ÎûÄÔºü.mp3!\n",
      "\n",
      "=======================\n",
      "\n",
      "üîó YouTube URL: https://youtu.be/GEYxeMYMtE4\n",
      "\n",
      "ü§ñ Whisper Model: base\n",
      "\n",
      "=======================\n",
      "\n",
      "==> Transcribing audio\n",
      "Detected language: Korean\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 125648/125648 [01:19<00:00, 1570.74frames/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==> Creating .txt file\n",
      "Transcription saved as .txt file at: outputs\\[ÏãúÍ≥ÑÏó¥] Ch1. Îç∞Ïù¥ÌÑ∞ÏôÄ Ïù∏Í≥µÏßÄÎä•, Í∑∏Î¶¨Í≥† Îç∞Ïù¥ÌÑ∞ Î∂ÑÏÑùÏù¥ÎûÄÔºü.txt\n",
      "\n",
      "‚ú® All Done!\n",
      "=======================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "result = transcribe_audio(mode=\"youtube\", output_formats=[\"txt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HF_KOR_STT_pjt-LslUj6mJ",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
